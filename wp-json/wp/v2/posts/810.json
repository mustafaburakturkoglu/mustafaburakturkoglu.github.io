{"id":810,"date":"2021-04-02T02:09:00","date_gmt":"2021-04-02T02:09:00","guid":{"rendered":"http:\/\/wp-io.dolby.net\/?p=810"},"modified":"2022-01-27T11:56:38","modified_gmt":"2022-01-27T19:56:38","slug":"recording-audio-on-android-with-examples","status":"publish","type":"post","link":"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/","title":{"rendered":"Recording Audio on Android with Examples"},"content":{"rendered":"\n<p>Knowing how to effectively record audio from a phone is valuable for mobile developers, but is especially essential for apps that use services like&nbsp;<a href=\"https:\/\/dolby.io\/\">Dolby.io<\/a>&nbsp;to process media. The wide range of hardware in Android devices can make it difficult to develop applications that need to capture and play back audio. However, Android provides several media frameworks to abstract the audio recording process, and others have developed external libraries that make it possible to incorporate high-performance audio into an application. This article will explain how to use the <strong>MediaRecorder<\/strong>, <strong>MediaPlayer<\/strong>, <strong>AudioRecord<\/strong>, and <strong>AudioTrack<\/strong> frameworks in Java, touch briefly on other options for audio capture and playback, and lastly will review their respective pros and cons.&nbsp;<\/p>\n\n\n\n<blockquote class=\"wp-block-quote\"><p><strong>Note<\/strong>: <em>You can find a sample application that uses these classes in the <a href=\"https:\/\/github.com\/dolbyio-samples\/blog-android-audio-recording-examples\">dolbyio-samples\/blog-android-audio-recording-examples<\/a> repository.<\/em><\/p><\/blockquote>\n\n\n\n<h1 id=\"h-what-is-mediarecorder\">What is MediaRecorder?<\/h1>\n\n\n\n<p>MediaRecorder is Android&#8217;s high-level framework for capturing audio and\/or video. It records to a file directly, which can then be played back using MediaPlayer (covered later in this post). An application specifies several parameters, namely the encoding and the file location, and MediaRecorder handles the rest. While relatively simple to configure, MediaRecorder offers minimal customizability, and is best for simple use cases when audio is not central to the functionality of the app.&nbsp;<\/p>\n\n\n\n<h3 id=\"h-how-to-use-mediarecorder\">How to use MediaRecorder<\/h3>\n\n\n\n<p>The following steps and code samples&nbsp;demonstrate how to use MediaRecorder to record audio to a file in an application&#8217;s internal storage. If you need to record video as well, see&nbsp;<a href=\"https:\/\/developer.android.com\/guide\/topics\/media\/camera\">the official Android guide on the Camera API<\/a>.&nbsp;<\/p>\n\n\n\n<p>This example, as well as the following examples for other audio classes, will follow a general outline with steps as defined below:&nbsp;<\/p>\n\n\n\n<ol><li>Declare permissions (only needed once for an application)<\/li><li>Instantiate\/configure the object<\/li><li>Attempt to start recording\/playback<\/li><\/ol>\n\n\n\n<p>As with all applications that need access to an audio input, declare the permission in the AndroidManifest.xml file. For API level 23 and above, the application should request permission to record audio the first time the user interacts with it.<\/p>\n\n\n\n<pre class=\"wp-block-prismatic-blocks\"><code class=\"language-markup\">&lt;uses-permission android:name=&quot;android.permission.RECORD_AUDIO&quot; \/&gt;<\/code><\/pre>\n\n\n\n<p>Next, instantiate MediaRecorder and set the necessary properties. Most commonly, this consists of setting an audio source, an output format, a file path, and an encoder. The order in which these calls are made matters; note that&nbsp;the file path and audio encoders can only be specified after an output format is set. Failure to pay attention to this order may result in IllegalStateExceptions being thrown.&nbsp;<\/p>\n\n\n\n<p>After the above properties&nbsp;are configured, the app should attempt to prepare the MediaRecorder object. If preparation is successful, the MediaRecorder is ready to use and can be started. Once started, the recording can be stopped, paused, and\/or subsequently resumed. The following&nbsp;state diagram&nbsp;depicts how the different method calls transition the MediaRecorder between different phases.<\/p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img loading=\"lazy\" width=\"650\" height=\"721\" src=\"https:\/\/dolby.io\/wp-content\/uploads\/2021\/04\/MediaRecorder.png\" alt=\"\" class=\"wp-image-812\" srcset=\"https:\/\/dolby.io\/wp-content\/uploads\/2021\/04\/MediaRecorder.png 650w, https:\/\/dolby.io\/wp-content\/uploads\/2021\/04\/MediaRecorder-270x300.png 270w\" sizes=\"(max-width: 650px) 100vw, 650px\" \/><\/figure>\n\n\n\n<p>Below is an example of how we might use MediaRecorder in a simple application. The&nbsp;<code>startRecording()<\/code>&nbsp;method can be called inside the onClickListener of a button, and takes as a parameter the location where the recording should be saved \u2013 for internal application storage, this can be obtained by calling&nbsp;<code>getFilesDir().getPath()<\/code>&nbsp;and appending a file name and format.<\/p>\n\n\n\n<blockquote class=\"wp-block-quote\"><p><strong>Note<\/strong>: <em>Many audio sources apply at least minimal processing to the raw stream by default. To record only the unprocessed signal, use the&nbsp;<code>UNPROCESSED<\/code>&nbsp;source, or&nbsp;<code>VOICE_RECOGNITION<\/code>&nbsp;for older devices that don&#8217;t support the unprocessed property.<\/em><\/p><\/blockquote>\n\n\n\n<pre class=\"wp-block-prismatic-blocks\"><code class=\"language-java\">protected MediaRecorder recorder;\n \nprivate void startRecording(String fileName) {\n        \/\/ initialize and configure MediaRecorder\n        recorder = new MediaRecorder();\n        recorder.setAudioSource(MediaRecorder.AudioSource.MIC);\n        recorder.setOutputFile(fileName);\n        recorder.setOutputFormat(MediaRecorder.OutputFormat.THREE_GPP);\n        recorder.setAudioEncoder(MediaRecorder.AudioEncoder.AAC);\n \n        try {\n            recorder.prepare();\n        }\n        catch (IOException e) {\n            \/\/ handle error\n        }\n        catch (IllegalStateException e) {\n            \/\/ handle error\n        }\n \n         \n        recorder.start();\n}<\/code><\/pre>\n\n\n\n<p>When the recording is finished, the application should release resources back to the operating system as soon as possible. The code below demonstrates how to properly end a recording.&nbsp;<\/p>\n\n\n\n<pre class=\"wp-block-prismatic-blocks\"><code class=\"language-java\">private void stopRecording() {\n        \/\/ stop recording and free up resources\n        recorder.stop();\n        recorder.release();\n \n        recorder = null;\n}<\/code><\/pre>\n\n\n\n<p>The final recording can be found at the storage location specified by the file path. To play back this recording, we can use MediaPlayer.&nbsp;<\/p>\n\n\n\n<h1 id=\"h-what-is-mediaplayer\">What is MediaPlayer?<\/h1>\n\n\n\n<p>MediaPlayer is MediaRecorder&#8217;s counterpart on Android. Given a URI, URL, or reference to a file, it plays audio or video with both minimal setup and minimal customizability. Once initialized, MediaPlayer can be started, paused, and stopped, providing straightforward playback. For a complete list of media formats supported by the Android platform, see&nbsp;<a href=\"https:\/\/developer.android.com\/guide\/topics\/media\/media-formats\">the official documentation<\/a>.&nbsp;<\/p>\n\n\n\n<h3 id=\"h-how-to-use-mediaplayer\">How to use MediaPlayer<\/h3>\n\n\n\n<p>An instance of MediaPlayer can be initialized in one of two ways: by instantiating it with the corresponding constructor and configuring the object, or by calling a convenience method create() that takes a data source. If choosing the latter, be aware that the create() method prepares the media synchronously, which may cause the UI thread to freeze. The examples in this section will demonstrate the first method.&nbsp;<\/p>\n\n\n\n<p>As with MediaRecorder, MediaPlayer has a myriad of different possible configurations and states that should be managed carefully to avoid errors. Refer to both the state diagram below and the rest of the official documentation.&nbsp;<\/p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img loading=\"lazy\" width=\"665\" height=\"813\" src=\"https:\/\/dolby.io\/wp-content\/uploads\/2021\/04\/mediaplayer_state_diagram.gif\" alt=\"\" class=\"wp-image-813\"\/><\/figure>\n\n\n\n<p>After instantiating the MediaPlayer object, the application can set any desired audio attributes, such as&nbsp;<a href=\"https:\/\/developer.android.com\/reference\/android\/media\/AudioAttributes\">specifying the media usage and content<\/a>. A data source must then be set, which can be a raw resource directly from your application, a path to an audio file in internal storage, or a URL of media to be streamed over the internet. Only after setting a data source can the MediaPlayer be prepared. For local files, this is acceptable to do synchronously, but for streaming purposes, the MediaPlayer should be prepared asynchronously and an O<code>nPreparedListener<\/code>&nbsp;should be set. The code below continues where our MediaRecorder example left off, showing how to play an audio file saved in an app&#8217;s internal storage.&nbsp;<\/p>\n\n\n\n<pre class=\"wp-block-prismatic-blocks\"><code class=\"language-java\">protected MediaPlayer player;\n \n \nprivate void startPlaying(String filePath) {\n        player = new MediaPlayer();\n        try {\n            player.setDataSource(filePath); \/\/ pass reference to file to be played\n            player.setAudioAttributes(new AudioAttributes.Builder().setContentType(AudioAttributes.CONTENT_TYPE_SPEECH)\n                                                                   .setUsage(AudioAttributes.USAGE_MEDIA)\n                                                                   .build()); \/\/ optional step\n            player.prepare(); \/\/ may take a while depending on the media, consider using .prepareAsync() for streaming\n        }\n        catch (IOException e) { \/\/ we need to catch both errors in case of invalid or inaccessible resources\n            \/\/ handle error\n        }\n        catch (IllegalArgumentException e) {\n            \/\/ handle error\n        }\n \n         \n        player.start();\n}<\/code><\/pre>\n\n\n\n<p>Like with MediaRecorder, it&#8217;s good practice to release the resources MediaPlayer uses once finished. When some user action, like a button press, stops playback, playback can be stopped as shown below. Otherwise, set an&nbsp;<code>OnCompletionListener<\/code>&nbsp;for MediaPlayer to release resources once the player reaches the end of the media source.&nbsp;<\/p>\n\n\n\n<pre class=\"wp-block-prismatic-blocks\"><code class=\"language-java\">private void stopPlaying() {\n        player.stop();\n        player.release(); \/\/ free up resources\n \n        player = null;\n}<\/code><\/pre>\n\n\n\n<h1 id=\"h-what-is-audiorecord\">What is AudioRecord?<\/h1>\n\n\n\n<p>AudioRecord removes a layer of abstraction between the application and a device&#8217;s audio hardware, recording uncompressed audio with no way to write directly to a file. These APIs are the lowest level audio framework for Android that can still be used in the Java and Kotlin layer. While MediaRecorder performs its data writing operations inside a black box, AudioRecord requires an application to periodically read the newest audio data from the AudioRecord object&#8217;s internal buffer. While this lower-level framework creates more complexity, it also allows applications to build more advanced audio functionality.&nbsp;<\/p>\n\n\n\n<h3 id=\"h-how-to-use-audiorecord\">How to use AudioRecord<\/h3>\n\n\n\n<p>After the application declares and obtains permission to record audio, an AudioRecord object can be initialized by passing several parameters into the constructor. (Alternatively, AudioRecord.Builder can be used, but the process is essentially the same for both). The constructor takes flags indicating the audio source, the sample rate in Hertz, whether the channel configuration is stereo or mono, and the size of the internal buffer for audio data. There are a few settings that are guaranteed to be supported on all Android devices; refer to the&nbsp;<a href=\"https:\/\/developer.android.com\/reference\/android\/media\/AudioRecord#AudioRecord(int,%20int,%20int,%20int,%20int)\">documentation<\/a>&nbsp;to maximize compatibility.<\/p>\n\n\n\n<blockquote class=\"wp-block-quote\"><p><strong>Note<\/strong>: <em>Make use of the&nbsp;<code>getMinBufferSize()<\/code>&nbsp;method when creating an AudioRecord object to ensure the internal buffer is sufficiently large given the device hardware. Also be sure to check that initialization didn&#8217;t fail silently before continuing. Both of these are demonstrated in the code sample below. Also note that we plan to write byte arrays, so we use 8-bit encoding, but be careful&nbsp;\u2013 this encoding is not necessary supported across devices. Use short arrays and 16-bit encoding to be fully sure of compatibility.&nbsp;<\/em><\/p><\/blockquote>\n\n\n\n<pre class=\"wp-block-prismatic-blocks\"><code class=\"language-java\">static final int AUDIO_SOURCE = MediaRecorder.AudioSource.MIC; \/\/ for raw audio, use MediaRecorder.AudioSource.UNPROCESSED, see note in MediaRecorder section\nstatic final int SAMPLE_RATE = 44100;\nstatic final int CHANNEL_CONFIG = AudioFormat.CHANNEL_IN_MONO;\nstatic final int AUDIO_FORMAT = AudioFormat.ENCODING_PCM_8BIT;\nstatic final int BUFFER_SIZE_RECORDING = AudioRecord.getMinBufferSize(SAMPLE_RATE, CHANNEL_CONFIG, AUDIO_FORMAT);\n \nprotected AudioRecord audioRecord;\n \nprivate void startRecording() {\n \n        audioRecord = new AudioRecord(AUDIO_SOURCE, SAMPLE_RATE, CHANNEL_CONFIG, AUDIO_FORMAT, BUFFER_SIZE_RECORDING);\n \n        if (audioRecord.getState() != AudioRecord.STATE_INITIALIZED) { \/\/ check for proper initialization\n            Log.e(TAG, &quot;error initializing &quot; + e.printStackTrace());\n            return;\n        }\n \n        audioRecord.startRecording();\n         \n}<\/code><\/pre>\n\n\n\n<p>To actually obtain the audio data, a separate thread should be dedicated to polling the AudioRecord object to avoid freezing the app&#8217;s UI. Create a new Thread with a custom implementation of Runnable. Inside the&nbsp;<code>run()<\/code>&nbsp;method, we continuously read data from AudioRecord into a buffer until an external event (e.g., the press of a button) indicates we should stop. In the code below, after the AudioRecord object has started recording, the&nbsp;<code>writeAudioData()<\/code>&nbsp;method is called inside the&nbsp;<code>run()<\/code>&nbsp;method of the thread we just made. While this post won&#8217;t go into detail on how to use threading, you can read through&nbsp;<a href=\"https:\/\/developer.android.com\/topic\/performance\/threads\">this Android guide<\/a>&nbsp;to learn more.&nbsp;<\/p>\n\n\n\n<p>We take the raw audio bytes and write them to a file. AudioRecord uses PCM encoding, so that&#8217;s the kind of data the file will hold. The&nbsp;<code>read()<\/code>&nbsp;method fills the passed in array with the amount of bytes requested in the third parameter, and returns the amount of bytes successfully read. The thread will block until enough samples have been captured to deliver the requested number, meaning that whatever operations are done with the filled buffer should be completed before the next batch of samples is ready. Here, we perform a file write for the sake of simplicity, but to ensure that no data is missed, we would ideally handle this writing in a separate thread with an independent buffer.&nbsp;<\/p>\n\n\n\n<p>As with all media capture frameworks, don&#8217;t forget to release the resources used by AudioRecord when finished.&nbsp;<\/p>\n\n\n\n<pre class=\"wp-block-prismatic-blocks\"><code class=\"language-java\">private void writeAudioData(String fileName) { \/\/ to be called in a Runnable for a Thread created after call to startRecording()\n \n        byte[] data = new byte[BUFFER_SIZE_RECORDING\/2]; \/\/ assign size so that bytes are read in in chunks inferior to AudioRecord internal buffer size\n \n        FileOutputStream outputStream = null;\n \n        try {\n            outputStream = new FileOutputStream(fileName); \/\/fileName is path to a file, where audio data should be written\n        } catch (FileNotFoundException e) {\n            \/\/ handle error\n        }\n \n        while (continueRecording) { \/\/ continueRecording can be toggled by a button press, handled by the main (UI) thread\n            int read = audioRecord.read(data, 0, data.length);\n            try {\n                outputStream.write(data, 0, read);\n            }\n            catch (IOException e) {\n                Log.d(TAG, &quot;exception while writing to file&quot;);\n                e.printStackTrace();\n            }\n        }\n \n        try {\n            outputStream.flush();\n            outputStream.close();\n        }\n        catch (IOException e) {\n            Log.d(TAG, &quot;exception while closing output stream &quot; + e.toString());\n            e.printStackTrace();\n        }\n \n        \/\/ Clean up\n        audioRecord.stop();\n        audioRecord.release();\n        audioRecord = null;\n \n    }<\/code><\/pre>\n\n\n\n<h1 id=\"h-what-is-audiotrack\">What is AudioTrack?<\/h1>\n\n\n\n<p>Just like MediaRecorder and MediaPlayer, AudioRecord and AudioTrack can be used in tandem. The flow of data is pretty much the opposite of that for AudioRecord&nbsp;\u2013 PCM data from a file or other source is periodically pushed by the application to the AudioTrack object, which sends it to the device&#8217;s hardware to be consumed and played. AudioTrack can be used to either stream audio continuously or play short sounds that fit in memory (for example, sound effects in a mobile game).&nbsp;<\/p>\n\n\n\n<h3 id=\"h-how-to-use-audiotrack\">How to use AudioTrack<\/h3>\n\n\n\n<p>Construct an instance of AudioTrack by passing the constructor parameters to configure the object, similar to AudioRecord. For API levels less than 21, the constructor takes specifications like the sample rate channel configuration type, and optionally a session ID to control which&nbsp;<a href=\"https:\/\/developer.android.com\/reference\/android\/media\/audiofx\/AudioEffect\">AudioEffects<\/a>&nbsp;are applied to specific instances of AudioTrack or other media players. For newer API levels, however, this constructor is deprecated, and an application should use either&nbsp;<a href=\"https:\/\/developer.android.com\/reference\/android\/media\/AudioTrack.Builder\">AudioTrack.Builder&nbsp;<\/a>(API 23) or an AudioTrack constructor that takes AudioAttributes and AudioFormat objects (API 21).<\/p>\n\n\n\n<p>The example below uses the constructor method to initialize AudioTrack. While the static variables may look identical to the ones declared for AudioRecord, note the differences in the channel configuration (<code>CHANNEL_OUT_MONO<\/code>) and buffer size (<code>AudioTrack.getMinBufferSize()<\/code>) flags that indicate these parameters are used for output, not input.&nbsp;<\/p>\n\n\n\n<blockquote class=\"wp-block-quote\"><p><strong>Note<\/strong>: <em>The same disclaimer above applies \u2013 we&#8217;re using 8-bit encoding at the risk of losing support on some Android devices, just to simplify the data writing process. One last thing to note in the constructor of AudioTrack: the media being played is from a file, too large to fit in memory, so the streaming mode is more appropriate for this use case.<\/em>&nbsp;<\/p><\/blockquote>\n\n\n\n<pre class=\"wp-block-prismatic-blocks\"><code class=\"language-java\">static final int SAMPLE_RATE = 44100;\nstatic final int CHANNEL_CONFIG = AudioFormat.CHANNEL_OUT_MONO;\nstatic final int AUDIO_FORMAT = AudioFormat.ENCODING_PCM_8BIT;\nstatic final int BUFFER_SIZE_PLAYING = AudioTrack.getMinBufferSize(SAMPLE_RATE, CHANNEL_CONFIG, AUDIO_FORMAT);\n \nprotected AudioTrack audioTrack;\n \nprivate void startPlaying() {\n \n    AudioAttributes audioAttributes = new AudioAttributes.Builder()\n                                    .setContentType(AudioAttributes.CONTENT_TYPE_SPEECH) \/\/ defines the type of content being played\n                                    .setUsage(AudioAttributes.USAGE_MEDIA) \/\/ defines the purpose of why audio is being played in the app\n                                    .build();\n \n    AudioFormat audioFormat = new AudioFormat.Builder()\n                            .setEncoding(AudioFormat.ENCODING_PCM_8BIT) \/\/ we plan on reading byte arrays of data, so use the corresponding encoding\n                            .setSampleRate(SAMPLE_RATE)\n                            .setChannelMask(AudioFormat.CHANNEL_OUT_MONO)\n                            .build();\n \n    audioTrack = new AudioTrack(audioAttributes, audioFormat, BUFFER_SIZE_PLAYING, AudioTrack.MODE_STREAM, AudioManager.AUDIO_SESSION_ID_GENERATE);\n \n}<\/code><\/pre>\n\n\n\n<p>To push data to the AudioTrack object to be played, we can follow the same pattern as we did for AudioRecord. Inside a dedicated thread, override the run method and make a call to&nbsp;<code>readAudioData()<\/code>, which does the bulk of the work. In it, we open a file input stream to read bytes of data from a recording, and write that data to the AudioTrack object. The write method is overloaded; see the&nbsp;<a href=\"https:\/\/developer.android.com\/reference\/android\/media\/AudioTrack#write(float%5B%5D,%20int,%20int,%20int)\">documentation<\/a>&nbsp;for other ways to give data to AudioTrack. Lastly, clean up memory and resources after playback has finished.&nbsp;<\/p>\n\n\n\n<pre class=\"wp-block-prismatic-blocks\"><code class=\"language-java\">private void readAudioData(String fileName) { \/\/ fileName is the path to the file where the audio data is located\n \n        byte[] data = new byte[BUFFER_SIZE_PLAYING\/2]; \/\/ small buffer size to not overflow AudioTrack&#039;s internal buffer\n \n        FileInputStream fileInputStream = null;\n \n        try {\n            fileInputStream = new FileInputStream(new File(fileName));\n        }\n        catch (IOException e) {\n            \/\/ handle exception\n        }\n \n        int i = 0;\n        while (i != -1) { \/\/ run until file ends\n            try {\n                i = fileInputStream.read(data);\n                audioTrack.write(data, 0, i);\n            }\n            catch (IOException e) {\n                \/\/ handle exception\n            }\n        }\n \n        try {\n            fileInputStream.close();\n        }\n        catch (IOException e) {\n            \/\/ handle exception\n        }\n \n        audioTrack.stop();\n        audioTrack.release();\n        audioTrack = null;\n}<\/code><\/pre>\n\n\n\n<h1 id=\"h-other-options\">Other options<\/h1>\n\n\n\n<p>While MediaRecorder and AudioRecorder are the only built-in ways to record audio, they are by no means the only ones available to Android developers. Widely used libraries include ExoPlayer as an alternative to MediaPlayer and several C++ libraries for high performance audio.&nbsp;<\/p>\n\n\n\n<p><a href=\"https:\/\/developer.android.com\/guide\/topics\/media\/exoplayer\">ExoPlayer<\/a>&nbsp;is an open source library for media playback, maintained by Google but not distributed as part of the Android SDK. Its structure is easily extendable and has features that are especially useful for streaming media over the internet. An instance of ExoPlayer takes custom MediaSource objects that can be built to correspond to the type and properties of the media, allowing an app to create custom configurations and maximize quality. To explore more capabilities of ExoPlayer, refer to the&nbsp;<a href=\"https:\/\/exoplayer.dev\/\">official developer guides<\/a>. If your audio flow includes recording using AudioRecord and playing back using ExoPlayer, keep in mind that ExoPlayer doesn&#8217;t support PCM-encoded files (an easy fix is to add a WAV header to the raw file).&nbsp;<\/p>\n\n\n\n<p>For applications where low latency and\/or high performance is vital to audio features, you could consider using libraries written in C or C++ and incorporating them in your app using the Android NDK toolset.&nbsp;<a href=\"https:\/\/developer.android.com\/ndk\/guides\/audio\/opensl\/opensl-for-android\">OpenSL ES<\/a>&nbsp;is an API that operates at a lower level, standardizing audio functionality access across platforms and allowing applications to use hardware acceleration. OpenSL ES is ideal for multimedia creation apps (synthesizers, DJ apps, etc), mobile games, and similar applications.&nbsp;<a href=\"https:\/\/developer.android.com\/ndk\/guides\/audio\/opensl\">The Android NDK comes with its own OS-specific implementation of OpenSL ES<\/a>. Also on the C side,&nbsp;<a href=\"https:\/\/developer.android.com\/ndk\/guides\/audio\/aaudio\/aaudio\">AAudio<\/a>&nbsp;is a relatively new API released by Google with similar use cases as OpenSL ES, designed to be fast and minimalist. Applications read or write data to AAudio streams, which are connected to pieces of audio hardware.&nbsp;<\/p>\n\n\n\n<p>If compatibility across API levels is important for your application,&nbsp;<a href=\"https:\/\/github.com\/google\/oboe\">Oboe<\/a>&nbsp;is a C++ wrapper that switches between the OpenSL ES and AAudio APIs to give the best performance for a specific Android device&#8217;s hardware. Google encourages developers to consider using Oboe for real-time audio applications to take advantage of AAudio&#8217;s features while maintaining backwards compatibility.&nbsp;<\/p>\n\n\n\n<h1 id=\"h-what-should-i-use\">What should I use?<\/h1>\n\n\n\n<p>After learning about the multitudes of options for audio recording and playback, the natural question is what to use for your specific application.&nbsp;Picking between frameworks and APIs always comes with tradeoffs, and the decision between audio libraries on Android is no different.&nbsp;For applications where performance&nbsp;isn&#8217;t a priority, or audio makes up a small component of the functionality, MediaRecorder and MediaPlayer might be an ideal combination to capture and play back audio without writing much complex code. Keep in mind that only the most common audio formats are supported, and the application won&#8217;t have access to the audio data as it&#8217;s being recorded. If you&#8217;re looking to perform some audio processing or otherwise need real-time audio, consider using AudioRecord and AudioTrack. The process of reading and writing data is more involved than using MediaRecorder, and any compression or transcoding can&#8217;t be done using the AudioRecord APIs. Another option is using AudioRecord to capture audio, then integrating ExoPlayer into the app for more extendable playback features. Lastly, C and C++ libraries facilitate the development of high performance audio applications, but require more domain-specific knowledge to use (as well as knowledge of a C-based language). Out of these libraries, Oboe is a good option \u2013 well-maintained with an active developer community.&nbsp;<\/p>\n\n\n\n<p>Here&#8217;s a table to see at a quick glance which option might be appropriate for your application.<\/p>\n\n\n\n<figure class=\"wp-block-table is-style-stripes\"><table><thead><tr><th><\/th><th>MediaRecorder<br>\/ MediaPlayer<\/th><th>AudioRecord<br>\/ AudioTrack<\/th><th>ExoPlayer<\/th><th>OpenSLES<\/th><th>AAudio<\/th><\/tr><\/thead><tbody><tr><td><strong>What works out of the box<\/strong><\/td><td>\u2705<\/td><td>\u274c<\/td><td>\u2705<\/td><td>\u274c<\/td><td>\u274c<\/td><\/tr><tr><td><strong>Language<\/strong><\/td><td>Java\/Kotlin<\/td><td>Java\/Kotlin<\/td><td>Java\/Kotlin<\/td><td>C<\/td><td>C<\/td><\/tr><tr><td><strong>High Performance<\/strong><\/td><td>\u274c<\/td><td>\u2705<\/td><td>\u2705<\/td><td>\u2705<\/td><td>\u2705<\/td><\/tr><tr><td><strong>Access to Recording Audio Buffer<\/strong><\/td><td>\u274c<\/td><td>\u2705<\/td><td>\u274c<\/td><td>\u2705<\/td><td>\u2705<\/td><\/tr><tr><td><strong>Video<\/strong><\/td><td>\u2705<\/td><td>\u274c<\/td><td>\u2705<\/td><td>\u274c<\/td><td>\u274c<\/td><\/tr><tr><td><strong>Backwards-compatible<\/strong><\/td><td>\u2705<\/td><td>\u2705<\/td><td>\u2705<\/td><td>\u2705<\/td><td>\u274c<\/td><\/tr><\/tbody><\/table><\/figure>\n\n\n\n<p>Ultimately, the best audio library to use will vary drastically depending on the scope and features of your application.&nbsp;<\/p>\n\n\n\n<p>This article&nbsp;has outlined how to use several of the most common Android frameworks for audio, but plenty of other guides and resources exist online to help you learn more. Best of luck on your journey to create great audio experiences within your Android application!&nbsp;<\/p>\n\n\n\n<blockquote class=\"wp-block-quote\"><p><strong>Attribution<\/strong>: <em>Portions of this page are reproduced from work created and&nbsp;<a href=\"https:\/\/code.google.com\/p\/android\/\">shared by the Android Open Source Project<\/a>&nbsp;and used according to terms described in the&nbsp;&nbsp;<a href=\"https:\/\/creativecommons.org\/licenses\/by\/4.0\/\">Creative Commons 3.0 Attribution License<\/a>.<\/em><\/p><\/blockquote>\n\n\n\n<p><\/p>\n","protected":false},"excerpt":{"rendered":"<p>How-to get started recording audio on Android with the most common libraries compared.<\/p>\n","protected":false},"author":21,"featured_media":2060,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":{"inline_featured_image":false,"_genesis_hide_title":false,"_genesis_hide_breadcrumbs":false,"_genesis_hide_singular_image":false,"_genesis_hide_footer_widgets":false,"_genesis_custom_body_class":"","_genesis_custom_post_class":"","_genesis_layout":""},"categories":[9,10],"tags":[26],"acf":[],"yoast_head":"<!-- This site is optimized with the Yoast SEO Premium plugin v17.2 (Yoast SEO v18.5.1) - https:\/\/yoast.com\/wordpress\/plugins\/seo\/ -->\n<title>Recording Audio on Android with Examples - Dolby.io<\/title>\n<meta name=\"description\" content=\"Android offers MediaRecorder, MediaPlayer, AudioRecord, and AudioTrack to record audio, plus external libraries to embed high-performance audio into applications.\" \/>\n<meta name=\"robots\" content=\"index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1\" \/>\n<link rel=\"canonical\" href=\"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/\" \/>\n<meta property=\"og:locale\" content=\"en_US\" \/>\n<meta property=\"og:type\" content=\"article\" \/>\n<meta property=\"og:title\" content=\"Recording Audio on Android with Examples\" \/>\n<meta property=\"og:description\" content=\"How-to get started recording audio on Android with the most common libraries compared.\" \/>\n<meta property=\"og:url\" content=\"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/\" \/>\n<meta property=\"og:site_name\" content=\"Dolby.io\" \/>\n<meta property=\"article:published_time\" content=\"2021-04-02T02:09:00+00:00\" \/>\n<meta property=\"article:modified_time\" content=\"2022-01-27T19:56:38+00:00\" \/>\n<meta property=\"og:image\" content=\"https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/Recording-Audio-on-Android-with-Examples.jpg\" \/>\n\t<meta property=\"og:image:width\" content=\"1088\" \/>\n\t<meta property=\"og:image:height\" content=\"450\" \/>\n\t<meta property=\"og:image:type\" content=\"image\/jpeg\" \/>\n<meta name=\"twitter:card\" content=\"summary_large_image\" \/>\n<meta name=\"twitter:label1\" content=\"Written by\" \/>\n\t<meta name=\"twitter:data1\" content=\"Megan Ren\" \/>\n\t<meta name=\"twitter:label2\" content=\"Est. reading time\" \/>\n\t<meta name=\"twitter:data2\" content=\"14 minutes\" \/>\n<script type=\"application\/ld+json\" class=\"yoast-schema-graph\">{\"@context\":\"https:\/\/schema.org\",\"@graph\":[{\"@type\":\"Organization\",\"@id\":\"https:\/\/dolby.io\/#organization\",\"name\":\"Dolby.io\",\"url\":\"https:\/\/dolby.io\/\",\"sameAs\":[],\"logo\":{\"@type\":\"ImageObject\",\"@id\":\"https:\/\/dolby.io\/#logo\",\"inLanguage\":\"en-US\",\"url\":\"https:\/\/dolby.io\/wp-content\/uploads\/2021\/07\/DolbyIO-favicon.png\",\"contentUrl\":\"https:\/\/dolby.io\/wp-content\/uploads\/2021\/07\/DolbyIO-favicon.png\",\"width\":512,\"height\":512,\"caption\":\"Dolby.io\"},\"image\":{\"@id\":\"https:\/\/dolby.io\/#logo\"}},{\"@type\":\"WebSite\",\"@id\":\"https:\/\/dolby.io\/#website\",\"url\":\"https:\/\/dolby.io\/\",\"name\":\"Dolby.io\",\"description\":\"Dolby.io\",\"publisher\":{\"@id\":\"https:\/\/dolby.io\/#organization\"},\"potentialAction\":[{\"@type\":\"SearchAction\",\"target\":{\"@type\":\"EntryPoint\",\"urlTemplate\":\"https:\/\/dolby.io\/?s={search_term_string}\"},\"query-input\":\"required name=search_term_string\"}],\"inLanguage\":\"en-US\"},{\"@type\":\"ImageObject\",\"@id\":\"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/#primaryimage\",\"inLanguage\":\"en-US\",\"url\":\"https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/Recording-Audio-on-Android-with-Examples.jpg\",\"contentUrl\":\"https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/Recording-Audio-on-Android-with-Examples.jpg\",\"width\":1088,\"height\":450},{\"@type\":\"WebPage\",\"@id\":\"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/#webpage\",\"url\":\"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/\",\"name\":\"Recording Audio on Android with Examples - Dolby.io\",\"isPartOf\":{\"@id\":\"https:\/\/dolby.io\/#website\"},\"primaryImageOfPage\":{\"@id\":\"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/#primaryimage\"},\"datePublished\":\"2021-04-02T02:09:00+00:00\",\"dateModified\":\"2022-01-27T19:56:38+00:00\",\"description\":\"Android offers MediaRecorder, MediaPlayer, AudioRecord, and AudioTrack to record audio, plus external libraries to embed high-performance audio into applications.\",\"breadcrumb\":{\"@id\":\"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/#breadcrumb\"},\"inLanguage\":\"en-US\",\"potentialAction\":[{\"@type\":\"ReadAction\",\"target\":[\"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/\"]}]},{\"@type\":\"BreadcrumbList\",\"@id\":\"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/#breadcrumb\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"Home\",\"item\":\"https:\/\/dolby.io\/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"Recording Audio on Android with Examples\"}]},{\"@type\":\"Article\",\"@id\":\"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/#article\",\"isPartOf\":{\"@id\":\"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/#webpage\"},\"author\":{\"@id\":\"https:\/\/dolby.io\/#\/schema\/person\/b208e8fd780c107da7455a37bcf5743c\"},\"headline\":\"Recording Audio on Android with Examples\",\"datePublished\":\"2021-04-02T02:09:00+00:00\",\"dateModified\":\"2022-01-27T19:56:38+00:00\",\"mainEntityOfPage\":{\"@id\":\"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/#webpage\"},\"wordCount\":2596,\"commentCount\":0,\"publisher\":{\"@id\":\"https:\/\/dolby.io\/#organization\"},\"image\":{\"@id\":\"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/#primaryimage\"},\"thumbnailUrl\":\"https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/Recording-Audio-on-Android-with-Examples.jpg\",\"keywords\":[\"android\"],\"articleSection\":[\"Developer\",\"Media\"],\"inLanguage\":\"en-US\",\"potentialAction\":[{\"@type\":\"CommentAction\",\"name\":\"Comment\",\"target\":[\"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/#respond\"]}]},{\"@type\":\"Person\",\"@id\":\"https:\/\/dolby.io\/#\/schema\/person\/b208e8fd780c107da7455a37bcf5743c\",\"name\":\"Megan Ren\",\"image\":{\"@type\":\"ImageObject\",\"@id\":\"https:\/\/dolby.io\/#personlogo\",\"inLanguage\":\"en-US\",\"url\":\"https:\/\/secure.gravatar.com\/avatar\/27212012493a11912a513e48f3f7ffdb?s=96&d=mm&r=g\",\"contentUrl\":\"https:\/\/secure.gravatar.com\/avatar\/27212012493a11912a513e48f3f7ffdb?s=96&d=mm&r=g\",\"caption\":\"Megan Ren\"},\"url\":\"https:\/\/dolby.io\/blog\/author\/mzren\/\"}]}<\/script>\n<!-- \/ Yoast SEO Premium plugin. -->","yoast_head_json":{"title":"Recording Audio on Android with Examples - Dolby.io","description":"Android offers MediaRecorder, MediaPlayer, AudioRecord, and AudioTrack to record audio, plus external libraries to embed high-performance audio into applications.","robots":{"index":"index","follow":"follow","max-snippet":"max-snippet:-1","max-image-preview":"max-image-preview:large","max-video-preview":"max-video-preview:-1"},"canonical":"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/","og_locale":"en_US","og_type":"article","og_title":"Recording Audio on Android with Examples","og_description":"How-to get started recording audio on Android with the most common libraries compared.","og_url":"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/","og_site_name":"Dolby.io","article_published_time":"2021-04-02T02:09:00+00:00","article_modified_time":"2022-01-27T19:56:38+00:00","og_image":[{"width":1088,"height":450,"url":"https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/Recording-Audio-on-Android-with-Examples.jpg","type":"image\/jpeg"}],"twitter_card":"summary_large_image","twitter_misc":{"Written by":"Megan Ren","Est. reading time":"14 minutes"},"schema":{"@context":"https:\/\/schema.org","@graph":[{"@type":"Organization","@id":"https:\/\/dolby.io\/#organization","name":"Dolby.io","url":"https:\/\/dolby.io\/","sameAs":[],"logo":{"@type":"ImageObject","@id":"https:\/\/dolby.io\/#logo","inLanguage":"en-US","url":"https:\/\/dolby.io\/wp-content\/uploads\/2021\/07\/DolbyIO-favicon.png","contentUrl":"https:\/\/dolby.io\/wp-content\/uploads\/2021\/07\/DolbyIO-favicon.png","width":512,"height":512,"caption":"Dolby.io"},"image":{"@id":"https:\/\/dolby.io\/#logo"}},{"@type":"WebSite","@id":"https:\/\/dolby.io\/#website","url":"https:\/\/dolby.io\/","name":"Dolby.io","description":"Dolby.io","publisher":{"@id":"https:\/\/dolby.io\/#organization"},"potentialAction":[{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https:\/\/dolby.io\/?s={search_term_string}"},"query-input":"required name=search_term_string"}],"inLanguage":"en-US"},{"@type":"ImageObject","@id":"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/#primaryimage","inLanguage":"en-US","url":"https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/Recording-Audio-on-Android-with-Examples.jpg","contentUrl":"https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/Recording-Audio-on-Android-with-Examples.jpg","width":1088,"height":450},{"@type":"WebPage","@id":"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/#webpage","url":"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/","name":"Recording Audio on Android with Examples - Dolby.io","isPartOf":{"@id":"https:\/\/dolby.io\/#website"},"primaryImageOfPage":{"@id":"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/#primaryimage"},"datePublished":"2021-04-02T02:09:00+00:00","dateModified":"2022-01-27T19:56:38+00:00","description":"Android offers MediaRecorder, MediaPlayer, AudioRecord, and AudioTrack to record audio, plus external libraries to embed high-performance audio into applications.","breadcrumb":{"@id":"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/#breadcrumb"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/"]}]},{"@type":"BreadcrumbList","@id":"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/#breadcrumb","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https:\/\/dolby.io\/"},{"@type":"ListItem","position":2,"name":"Recording Audio on Android with Examples"}]},{"@type":"Article","@id":"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/#article","isPartOf":{"@id":"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/#webpage"},"author":{"@id":"https:\/\/dolby.io\/#\/schema\/person\/b208e8fd780c107da7455a37bcf5743c"},"headline":"Recording Audio on Android with Examples","datePublished":"2021-04-02T02:09:00+00:00","dateModified":"2022-01-27T19:56:38+00:00","mainEntityOfPage":{"@id":"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/#webpage"},"wordCount":2596,"commentCount":0,"publisher":{"@id":"https:\/\/dolby.io\/#organization"},"image":{"@id":"https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/#primaryimage"},"thumbnailUrl":"https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/Recording-Audio-on-Android-with-Examples.jpg","keywords":["android"],"articleSection":["Developer","Media"],"inLanguage":"en-US","potentialAction":[{"@type":"CommentAction","name":"Comment","target":["https:\/\/dolby.io\/blog\/recording-audio-on-android-with-examples\/#respond"]}]},{"@type":"Person","@id":"https:\/\/dolby.io\/#\/schema\/person\/b208e8fd780c107da7455a37bcf5743c","name":"Megan Ren","image":{"@type":"ImageObject","@id":"https:\/\/dolby.io\/#personlogo","inLanguage":"en-US","url":"https:\/\/secure.gravatar.com\/avatar\/27212012493a11912a513e48f3f7ffdb?s=96&d=mm&r=g","contentUrl":"https:\/\/secure.gravatar.com\/avatar\/27212012493a11912a513e48f3f7ffdb?s=96&d=mm&r=g","caption":"Megan Ren"},"url":"https:\/\/dolby.io\/blog\/author\/mzren\/"}]}},"uagb_featured_image_src":{"full":["https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/Recording-Audio-on-Android-with-Examples.jpg",1088,450,false],"thumbnail":["https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/Recording-Audio-on-Android-with-Examples-150x150.jpg",150,150,true],"medium":["https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/Recording-Audio-on-Android-with-Examples-300x124.jpg",300,124,true],"medium_large":["https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/Recording-Audio-on-Android-with-Examples-768x318.jpg",768,318,true],"large":["https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/Recording-Audio-on-Android-with-Examples-1024x424.jpg",1024,424,true],"1536x1536":["https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/Recording-Audio-on-Android-with-Examples.jpg",1088,450,false],"2048x2048":["https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/Recording-Audio-on-Android-with-Examples.jpg",1088,450,false],"featured-page":["https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/Recording-Audio-on-Android-with-Examples-1088x400.jpg",1088,400,true],"gb-block-post-grid-landscape":["https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/Recording-Audio-on-Android-with-Examples-600x400.jpg",600,400,true],"gb-block-post-grid-square":["https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/Recording-Audio-on-Android-with-Examples-600x450.jpg",600,450,true]},"uagb_author_info":{"display_name":"Megan Ren","author_link":"https:\/\/dolby.io\/blog\/author\/mzren\/"},"uagb_comment_info":0,"uagb_excerpt":"How-to get started recording audio on Android with the most common libraries compared.","featured_image_src":"https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/Recording-Audio-on-Android-with-Examples-600x400.jpg","featured_image_src_square":"https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/Recording-Audio-on-Android-with-Examples-600x450.jpg","author_info":{"display_name":"Megan Ren","author_link":"https:\/\/dolby.io\/blog\/author\/mzren\/"},"_links":{"self":[{"href":"https:\/\/dolby.io\/wp-json\/wp\/v2\/posts\/810"}],"collection":[{"href":"https:\/\/dolby.io\/wp-json\/wp\/v2\/posts"}],"about":[{"href":"https:\/\/dolby.io\/wp-json\/wp\/v2\/types\/post"}],"author":[{"embeddable":true,"href":"https:\/\/dolby.io\/wp-json\/wp\/v2\/users\/21"}],"replies":[{"embeddable":true,"href":"https:\/\/dolby.io\/wp-json\/wp\/v2\/comments?post=810"}],"version-history":[{"count":0,"href":"https:\/\/dolby.io\/wp-json\/wp\/v2\/posts\/810\/revisions"}],"wp:featuredmedia":[{"embeddable":true,"href":"https:\/\/dolby.io\/wp-json\/wp\/v2\/media\/2060"}],"wp:attachment":[{"href":"https:\/\/dolby.io\/wp-json\/wp\/v2\/media?parent=810"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https:\/\/dolby.io\/wp-json\/wp\/v2\/categories?post=810"},{"taxonomy":"post_tag","embeddable":true,"href":"https:\/\/dolby.io\/wp-json\/wp\/v2\/tags?post=810"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}