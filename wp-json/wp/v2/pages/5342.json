{"id":5342,"date":"2022-03-08T13:40:38","date_gmt":"2022-03-08T21:40:38","guid":{"rendered":"https:\/\/dolby.io\/?page_id=5342"},"modified":"2022-03-09T09:20:56","modified_gmt":"2022-03-09T17:20:56","slug":"audio-research","status":"publish","type":"page","link":"https:\/\/dolby.io\/audio-research\/","title":{"rendered":"Audio Research"},"content":{"rendered":"\n<div class=\"wp-block-genesis-blocks-gb-columns gpb-altitude-section-call-to-action dbio-headalt2 gb-layout-columns-1 gb-1-col-equal gb-background-cover gb-background-no-repeat gb-has-custom-text-color gb-columns-center alignfull\" style=\"padding-top:12em;padding-right:1.5em;padding-bottom:2em;padding-left:1.5em;color:#ffffff;background-image:url(https:\/\/staging.dolbyio.com\/wp-content\/uploads\/2021\/09\/bg-homev1.png);background-position:50% 12%\"><div class=\"gb-layout-column-wrap gb-block-layout-column-gap-3 gb-is-responsive-column\" style=\"max-width:835px\">\n<div class=\"wp-block-genesis-blocks-gb-column gb-block-layout-column\"><div class=\"gb-block-layout-column-inner\">\n<h1 class=\"has-text-align-center\" style=\"font-size:60px\">We\u2019re advancing the latest breakthroughs in audio AI<\/h1>\n\n\n\n<p class=\"has-text-align-center has-text-color\" style=\"color:#b9b9ba\">The Dolby Applied AI team advances the state of the art in audio processing by<br>using and developing core AI techniques.<\/p>\n<\/div><\/div>\n<\/div><\/div>\n\n\n\n<div class=\"wp-block-genesis-blocks-gb-columns dbio-approach dbio-tl-ir-v1 gb-layout-columns-2 gb-2-col-wideright gb-has-custom-background-color gb-columns-center alignfull\" style=\"padding-top:2em;padding-right:1.5em;padding-bottom:3em;padding-left:1.5em;background-color:#14141a\"><div class=\"gb-layout-column-wrap gb-block-layout-column-gap-0 gb-is-responsive-column\" style=\"max-width:1312px\">\n<div class=\"wp-block-genesis-blocks-gb-column gb-block-layout-column gb-is-vertically-aligned-center\"><div class=\"gb-block-layout-column-inner\">\n<h2 class=\"has-white-color has-text-color\" id=\"h-our-approach\">Our approach<\/h2>\n\n\n\n<div class=\"wp-block-image image-hideshow-d\"><figure class=\"aligncenter size-full\"><img src=\"https:\/\/staging.dolbyio.com\/wp-content\/uploads\/2022\/03\/illustration-audio-research-approach-dolbyio.png\" alt=\"\" class=\"wp-image-5291\"\/><\/figure><\/div>\n\n\n\n<p class=\"has-text-color\" style=\"color:#b9b9ba\">We work in an open research environment, leveraging the latest deep learning technologies, and contribute to the advancement of AI for audio. Our inventions both fuel progress in the field and provide competitive advantage to Dolby\u2019s products. Some of our research supports Dolby.io APIs.<\/p>\n<\/div><\/div>\n\n\n\n<div class=\"wp-block-genesis-blocks-gb-column gb-block-layout-column\"><div class=\"gb-block-layout-column-inner\">\n<div class=\"wp-block-image image-hide-m\"><figure class=\"aligncenter size-full\"><img src=\"https:\/\/staging.dolbyio.com\/wp-content\/uploads\/2022\/03\/illustration-audio-research-approach-dolbyio.png\" alt=\"\" class=\"wp-image-5291\"\/><\/figure><\/div>\n<\/div><\/div>\n<\/div><\/div>\n\n\n<section id=\"ai_researchers_block_block_6227cd1de852c\" class=\"dev_ai_res_blocks dbio_blocks force_extended_width force_fullscreen_width dbio_light_theme\" style=\"background-color: \">\n\t\r\n<div class=\"dbio-default-heading-block\">\r\n    <h2> Meet the Dolby Applied AI Researchers<\/h2>\r\n<\/div>\r\n\t\n\t<section class=\"twl_carousel_container\">\n\t\t<div class=\"dev_ai_res_nav\"><\/div>\n\t\t<div class=\"twl_carousel\" id=\"slider_ai_researchers_block_block_6227cd1de852c\"  >\n\t\t\t\t\t\t  \n\t\t\t\t\t<article class=\"ai_researcher_block\">  \n\t\t\t\t\t\t<div class=\"ai__main_content dbio_flex_aic\"> \n\t\t\t\t\t\t\t<div class=\"dbio_researchers_img\">\n\t\t\t\t\t\t\t\t <img src=\"https:\/\/dolby.io\/wp-content\/uploads\/2022\/03\/researcher-roy-fejgin-dolbyio.jpg\" alt=\"Roy Fejgin\" >\n\t\t\t\t\t\t\t<\/div>\n\t\t\t\t\t\t\t<div class=\"dbio_researchers_content\">\n\t\t\t\t\t\t\t\t<p class=\"dbio_rsai_name\">Roy Fejgin<\/p>\n\t\t\t\t\t\t\t\t<p class=\"dbio_rsai_title\">Researcher\t\t\t\t\t\t\t\t\t<\/p>\n\t\t\t\t\t\t\t<\/div> \n\t\t\t\t\t\t  \n\t\t\t\t\t\t<\/div>\n\t\t\t\t\t<\/article> \n\t\t\t\t\t\n\t\t\t\t  \t\t\t\t  \n\t\t\t\t\t<article class=\"ai_researcher_block\">  \n\t\t\t\t\t\t<div class=\"ai__main_content dbio_flex_aic\"> \n\t\t\t\t\t\t\t<div class=\"dbio_researchers_img\">\n\t\t\t\t\t\t\t\t <img src=\"https:\/\/dolby.io\/wp-content\/uploads\/2022\/03\/researcher-gauri-jagatap-dolbyio.jpg\" alt=\"Gauri Jagatap\" >\n\t\t\t\t\t\t\t<\/div>\n\t\t\t\t\t\t\t<div class=\"dbio_researchers_content\">\n\t\t\t\t\t\t\t\t<p class=\"dbio_rsai_name\">Gauri Jagatap<\/p>\n\t\t\t\t\t\t\t\t<p class=\"dbio_rsai_title\">Researcher\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span>,<\/span> <a target=\"_blank\" href=\"https:\/\/scholar.google.com\/citations?user=B7-TNaIAAAAJ&#038;hl=en\" class=\"dbio_google_scholar\"> Google Scholar <\/a>\n\t\t\t\t\t\t\t\t\t<\/p>\n\t\t\t\t\t\t\t<\/div> \n\t\t\t\t\t\t  \n\t\t\t\t\t\t<\/div>\n\t\t\t\t\t<\/article> \n\t\t\t\t\t\n\t\t\t\t  \t\t\t\t  \n\t\t\t\t\t<article class=\"ai_researcher_block\">  \n\t\t\t\t\t\t<div class=\"ai__main_content dbio_flex_aic\"> \n\t\t\t\t\t\t\t<div class=\"dbio_researchers_img\">\n\t\t\t\t\t\t\t\t <img src=\"https:\/\/dolby.io\/wp-content\/uploads\/2022\/03\/researcher-vivek-kumar-dolbyio.jpg\" alt=\"Vivek Kumar\" >\n\t\t\t\t\t\t\t<\/div>\n\t\t\t\t\t\t\t<div class=\"dbio_researchers_content\">\n\t\t\t\t\t\t\t\t<p class=\"dbio_rsai_name\">Vivek Kumar<\/p>\n\t\t\t\t\t\t\t\t<p class=\"dbio_rsai_title\">Director\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span>,<\/span> <a target=\"_blank\" href=\"https:\/\/scholar.google.com\/citations?hl=en&#038;user=fOexgn8AAAAJ\" class=\"dbio_google_scholar\"> Google Scholar <\/a>\n\t\t\t\t\t\t\t\t\t<\/p>\n\t\t\t\t\t\t\t<\/div> \n\t\t\t\t\t\t  \n\t\t\t\t\t\t<\/div>\n\t\t\t\t\t<\/article> \n\t\t\t\t\t\n\t\t\t\t  \t\t\t\t  \n\t\t\t\t\t<article class=\"ai_researcher_block\">  \n\t\t\t\t\t\t<div class=\"ai__main_content dbio_flex_aic\"> \n\t\t\t\t\t\t\t<div class=\"dbio_researchers_img\">\n\t\t\t\t\t\t\t\t <img src=\"https:\/\/dolby.io\/wp-content\/uploads\/2022\/03\/researcher-xiaoyu-liu-dolbyio.jpg\" alt=\"Xiaoyu Liu\" >\n\t\t\t\t\t\t\t<\/div>\n\t\t\t\t\t\t\t<div class=\"dbio_researchers_content\">\n\t\t\t\t\t\t\t\t<p class=\"dbio_rsai_name\">Xiaoyu Liu<\/p>\n\t\t\t\t\t\t\t\t<p class=\"dbio_rsai_title\">Researcher\t\t\t\t\t\t\t\t\t<\/p>\n\t\t\t\t\t\t\t<\/div> \n\t\t\t\t\t\t  \n\t\t\t\t\t\t<\/div>\n\t\t\t\t\t<\/article> \n\t\t\t\t\t\n\t\t\t\t  \t\t\t\t  \n\t\t\t\t\t<article class=\"ai_researcher_block\">  \n\t\t\t\t\t\t<div class=\"ai__main_content dbio_flex_aic\"> \n\t\t\t\t\t\t\t<div class=\"dbio_researchers_img\">\n\t\t\t\t\t\t\t\t <img src=\"https:\/\/dolby.io\/wp-content\/uploads\/2022\/03\/researcher-santiago-pascual-dolbyio.jpg\" alt=\"Santiago Pascual\" >\n\t\t\t\t\t\t\t<\/div>\n\t\t\t\t\t\t\t<div class=\"dbio_researchers_content\">\n\t\t\t\t\t\t\t\t<p class=\"dbio_rsai_name\">Santiago Pascual<\/p>\n\t\t\t\t\t\t\t\t<p class=\"dbio_rsai_title\">Researcher\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span>,<\/span> <a target=\"_blank\" href=\"https:\/\/scholar.google.com\/citations?hl=en&#038;user=7cVOyh0AAAAJ\" class=\"dbio_google_scholar\"> Google Scholar <\/a>\n\t\t\t\t\t\t\t\t\t<\/p>\n\t\t\t\t\t\t\t<\/div> \n\t\t\t\t\t\t  \n\t\t\t\t\t\t<\/div>\n\t\t\t\t\t<\/article> \n\t\t\t\t\t\n\t\t\t\t  \t\t\t\t  \n\t\t\t\t\t<article class=\"ai_researcher_block\">  \n\t\t\t\t\t\t<div class=\"ai__main_content dbio_flex_aic\"> \n\t\t\t\t\t\t\t<div class=\"dbio_researchers_img\">\n\t\t\t\t\t\t\t\t <img src=\"https:\/\/dolby.io\/wp-content\/uploads\/2022\/03\/researcher-jordi-pons-dolbyio.jpg\" alt=\"Jordi Pons\" >\n\t\t\t\t\t\t\t<\/div>\n\t\t\t\t\t\t\t<div class=\"dbio_researchers_content\">\n\t\t\t\t\t\t\t\t<p class=\"dbio_rsai_name\">Jordi Pons<\/p>\n\t\t\t\t\t\t\t\t<p class=\"dbio_rsai_title\">Researcher\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span>,<\/span> <a target=\"_blank\" href=\"https:\/\/scholar.google.com\/citations?hl=en&#038;user=wPzfRiwAAAAJ\" class=\"dbio_google_scholar\"> Google Scholar <\/a>\n\t\t\t\t\t\t\t\t\t<\/p>\n\t\t\t\t\t\t\t<\/div> \n\t\t\t\t\t\t  \n\t\t\t\t\t\t<\/div>\n\t\t\t\t\t<\/article> \n\t\t\t\t\t\n\t\t\t\t  \t\t\t\t  \n\t\t\t\t\t<article class=\"ai_researcher_block\">  \n\t\t\t\t\t\t<div class=\"ai__main_content dbio_flex_aic\"> \n\t\t\t\t\t\t\t<div class=\"dbio_researchers_img\">\n\t\t\t\t\t\t\t\t <img src=\"https:\/\/dolby.io\/wp-content\/uploads\/2022\/03\/researcher-joan-serra-dolbyio.jpg\" alt=\"Joan Serr\u00e0\" >\n\t\t\t\t\t\t\t<\/div>\n\t\t\t\t\t\t\t<div class=\"dbio_researchers_content\">\n\t\t\t\t\t\t\t\t<p class=\"dbio_rsai_name\">Joan Serr\u00e0<\/p>\n\t\t\t\t\t\t\t\t<p class=\"dbio_rsai_title\">Researcher\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span>,<\/span> <a target=\"_blank\" href=\"https:\/\/scholar.google.com\/citations?user=sZLj96sAAAAJ\" class=\"dbio_google_scholar\"> Google Scholar <\/a>\n\t\t\t\t\t\t\t\t\t<\/p>\n\t\t\t\t\t\t\t<\/div> \n\t\t\t\t\t\t  \n\t\t\t\t\t\t<\/div>\n\t\t\t\t\t<\/article> \n\t\t\t\t\t\n\t\t\t\t  \t\t<\/div> \n\t<\/section>\t\t\t \n<\/section> \n\n\n<div class=\"wp-block-genesis-blocks-gb-columns dbio-wave-rule gb-layout-columns-1 one-column gb-columns-center alignfull\" style=\"margin-top:52px;padding-top:6px;padding-bottom:6px\"><div class=\"gb-layout-column-wrap gb-block-layout-column-gap-0 gb-is-responsive-column\" style=\"max-width:1313px\">\n<div class=\"wp-block-genesis-blocks-gb-column gb-block-layout-column gb-is-vertically-aligned-bottom\"><div class=\"gb-block-layout-column-inner gb-has-custom-background-color\" style=\"margin-top:50px;padding-top:6px;background-color:#14141a;text-align:center\">\n<figure class=\"wp-block-image alignfull size-full\"><img loading=\"lazy\" width=\"1312\" height=\"12\" src=\"https:\/\/dolbydev.wpengine.com\/wp-content\/uploads\/2021\/09\/DolbyIO-Wave-Separator-White.png\" alt=\"\" class=\"wp-image-2579\" srcset=\"https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/DolbyIO-Wave-Separator-White.png 1312w, https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/DolbyIO-Wave-Separator-White-300x3.png 300w, https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/DolbyIO-Wave-Separator-White-1024x9.png 1024w, https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/DolbyIO-Wave-Separator-White-768x7.png 768w\" sizes=\"(max-width: 1312px) 100vw, 1312px\" \/><\/figure>\n<\/div><\/div>\n<\/div><\/div>\n\n\n\n<p><\/p>\n\n\n\n<section id=\"publications_block_block_6227c607f00cf\" class=\"dbio_blocks dbio_publications_block_container force_extended_width force_fullscreen_width \"   style=\"background-color: \">\n\n<div class=\"dbio_publications_main dioFadeInUp\">\n\n\t<div class=\"dbio_publications_title\">\n\t\t<h2 class=\"w3-animate-bottom\">Publications<\/h2>\n\t<\/div>\n\t<div class=\"dbio_publications_posts\">\n\t\t<div class=\"dbio_article_publications\">\n\t\t\t\t\t\t\t  <article class=\"dbio_pub_posts\"> \n\t\t\t\t\t\t<span class=\"publications_date \">Published July 7, 2021 <\/span>\n\t\t\t\t\t\t<h2><a target=\"_blank\" href=\"https:\/\/arxiv.org\/abs\/2107.03100\">Adversarial Auto-Encoding for Packet Loss Concealment<\/a><\/h2>\n\t\t\t\t\t\t<span class=\"publications_authors\">Authors: Santiago Pascual, Joan Serr\u00e0, Jordi Pons<\/span> \n\t\t\t\t\t\t<p>Communication technologies like voice over IP operate under constrained real-time conditions, with voice packets being subject to delays and losses from the network. In such cases, the packet loss concealment (PLC) algorithm reconstructs\u2026<\/p>\n\t\t\t\t  <\/article>\n\t\t\t\t\t\t\t\t  <article class=\"dbio_pub_posts\"> \n\t\t\t\t\t\t<span class=\"publications_date \">Published April 8, 2021 <\/span>\n\t\t\t\t\t\t<h2><a target=\"_blank\" href=\"https:\/\/arxiv.org\/abs\/2104.03725\">On tuning consistent annealed sampling for denoising score matching<\/a><\/h2>\n\t\t\t\t\t\t<span class=\"publications_authors\">Authors: Joan Serr\u00e0, Santiago Pascual, Jordi Pons<\/span> \n\t\t\t\t\t\t<p>Score-based generative models provide state-of-the-art quality for image and audio synthesis. Sampling from these models is performed iteratively, typically employing a discretized series of noise levels and a predefined scheme. In this note, we&#8230;<\/p>\n\t\t\t\t  <\/article>\n\t\t\t\t\t\t\t\t  <article class=\"dbio_pub_posts\"> \n\t\t\t\t\t\t<span class=\"publications_date \">Published February 11, 2021 <\/span>\n\t\t\t\t\t\t<h2><a target=\"_blank\" href=\"https:\/\/arxiv.org\/abs\/2102.06142\">Multichannel-based learning for audio object extraction<\/a><\/h2>\n\t\t\t\t\t\t<span class=\"publications_authors\">Authors: Daniel Arteaga, Jordi Pons<\/span> \n\t\t\t\t\t\t<p>The current paradigm for creating and deploying immersive audio content is based on audio objects, which are composed of an audio track and position metadata. While rendering an object-based production into a multichannel mix is&#8230;<\/p>\n\t\t\t\t  <\/article>\n\t\t\t\t\t\t\t\t  <article class=\"dbio_pub_posts\"> \n\t\t\t\t\t\t<span class=\"publications_date \">Published February 9, 2021 <\/span>\n\t\t\t\t\t\t<h2><a target=\"_blank\" href=\"https:\/\/arxiv.org\/abs\/2102.04945\">On permutation invariant training for speech source separation<\/a><\/h2>\n\t\t\t\t\t\t<span class=\"publications_authors\">Authors: Xiaoyu Liu, Jordi Pons<\/span> \n\t\t\t\t\t\t<p>We study permutation invariant training (PIT), which targets at the permutation ambiguity problem for speaker independent source separation models. We extend two state-of-the-art PIT strategies. First, we look at the two-stage&#8230;<\/p>\n\t\t\t\t  <\/article>\n\t\t\t\t\t\t\t\t  <article class=\"dbio_pub_posts\"> \n\t\t\t\t\t\t<span class=\"publications_date \">Published October 27, 2020 <\/span>\n\t\t\t\t\t\t<h2><a target=\"_blank\" href=\"https:\/\/arxiv.org\/abs\/2010.14356\">Upsampling artifacts in neural audio synthesis<\/a><\/h2>\n\t\t\t\t\t\t<span class=\"publications_authors\">Authors: Jordi Pons, Santiago Pascual, Giulio Cengarle, Joan Serr\u00e0<\/span> \n\t\t\t\t\t\t<p>A number of recent advances in neural audio synthesis rely on upsampling layers, which can introduce undesired artifacts. In computer vision, upsampling artifacts have been studied and are known as checkerboard artifacts (due to their&#8230;<\/p>\n\t\t\t\t  <\/article>\n\t\t\t\t\t\t\t\t  <article class=\"dbio_pub_posts\"> \n\t\t\t\t\t\t<span class=\"publications_date \">Published October 20, 2020 <\/span>\n\t\t\t\t\t\t<h2><a target=\"_blank\" href=\"https:\/\/arxiv.org\/abs\/2010.10291\">Automatic multitrack mixing with a differentiable mixing console of neural audio effects<\/a><\/h2>\n\t\t\t\t\t\t<span class=\"publications_authors\">Authors: Christian J. Steinmetz, Jordi Pons, Santiago Pascual, Joan Serr\u00e0<\/span> \n\t\t\t\t\t\t<p>Applications of deep learning to automatic multitrack mixing are largely unexplored. This is partly due to the limited available data, coupled with the fact that such data is relatively unstructured and variable. To address these challenges&#8230;<\/p>\n\t\t\t\t  <\/article>\n\t\t\t\t\t\t\t\t  <article class=\"dbio_pub_posts\"> \n\t\t\t\t\t\t<span class=\"publications_date \">Published October 1, 2020 <\/span>\n\t\t\t\t\t\t<h2><a target=\"_blank\" href=\"https:\/\/arxiv.org\/abs\/2010.00368\">SESQA: semi-supervised learning for speech quality assessment<\/a><\/h2>\n\t\t\t\t\t\t<span class=\"publications_authors\">Authors: Joan Serr\u00e0, Jordi Pons, Santiago Pascual<\/span> \n\t\t\t\t\t\t<p>Automatic speech quality assessment is an important, transversal task whose progress is hampered by the scarcity of human annotations, poor generalization to unseen recording conditions, and a lack of flexibility of existing approaches.<\/p>\n\t\t\t\t  <\/article>\n\t\t\t\t\t\t\t\t  <article class=\"dbio_pub_posts\"> \n\t\t\t\t\t\t<span class=\"publications_date \">Published February 20, 2020 <\/span>\n\t\t\t\t\t\t<h2><a target=\"_blank\" href=\"https:\/\/arxiv.org\/abs\/2002.08688\">An empirical study of Conv-TasNet<\/a><\/h2>\n\t\t\t\t\t\t<span class=\"publications_authors\">Authors: Berkan Kadioglu, Michael Horgan, Xiaoyu Liu, Jordi Pons, Dan Darcy, Vivek Kumar<\/span> \n\t\t\t\t\t\t<p>Conv-TasNet is a recently proposed waveform-based deep neural network that achieves state-of-the-art performance in speech source separation. Its architecture consists of a learnable encoder\/decoder and a separator that operates on top&#8230;<\/p>\n\t\t\t\t  <\/article>\n\t\t\t\t\t\t\t\t  <article class=\"dbio_pub_posts\"> \n\t\t\t\t\t\t<span class=\"publications_date \">Published January 20, 2020 <\/span>\n\t\t\t\t\t\t<h2><a target=\"_blank\" href=\"https:\/\/arxiv.org\/abs\/2001.09847\">Source coding of audio signals with a generative model<\/a><\/h2>\n\t\t\t\t\t\t<span class=\"publications_authors\">Authors: Roy Fejgin, Janusz Klejsa, Lars Villemoes, Cong Zhou<\/span> \n\t\t\t\t\t\t<p>We consider source coding of audio signals with the help of a generative model. We use a construction where a waveform is first quantized, yielding a finite bitrate representation. The waveformis then reconstructed by random sampling from&#8230;<\/p>\n\t\t\t\t  <\/article>\n\t\t\t\t\t\t\t\t  <article class=\"dbio_pub_posts\"> \n\t\t\t\t\t\t<span class=\"publications_date \">Published November 3, 2018 <\/span>\n\t\t\t\t\t\t<h2><a target=\"_blank\" href=\"https:\/\/arxiv.org\/abs\/1811.03021\">High-quality speech coding with SampleRNN<\/a><\/h2>\n\t\t\t\t\t\t<span class=\"publications_authors\">Authors: Janusz Klejsa, Per Hedelin, Cong Zhou, Roy Fejgin, Lars Villemoes<\/span> \n\t\t\t\t\t\t<p>We provide a speech coding scheme employing a generative model based on SampleRNN that, while operating at significantly lower bitrates, matches or surpasses the perceptual quality of state-of-the-art classic wide-band codecs.<\/p>\n\t\t\t\t  <\/article>\n\t\t\t\t \t\t\n\t\t<\/div> \t\t\n\t\t\t\t\t<div class=\"dbio_pub_pagination\">   \n\t\t\t\t<button id=\"more_posts\" data-posts_per_page=\"10\" data-max_num_pages=\"2\" data-found_posts=\"11\" class=\" dbio-default-button dbio-default-button dbp_pagination\" value=\"Load More\">Load More<\/button>\n\t\t\t<\/div> \n\t\t\t\t <\/div> \n<\/div>   \n<\/section> \n\n\r\n\r\n<section id=\"latest_news_block_block_6227c62ef00d0\" class=\"dbio_blocks dbio_latest_news_block_container  force_fullscreen_width dbio_light_theme\" style=\"background-color: \">\r\n \r\n\t<section class=\"dbio_latest_news_main force_extended_width twl_carousel_container\">\r\n\t\t\r\n\t\t<div class=\"dbio_latest_news_head\">\r\n\t\t\t<div class=\"dbio_latest_news_heading\">\r\n\t\t\t\t<h2>Latest news and events<\/h2>\r\n\t\t\t<\/div>\r\n\t\t\t<div class=\"dev_latest_news_nav\"><\/div> \r\n\t\t<\/div>\r\n\t\t\r\n\t\t<div class=\"twl_carousel\" id=\"slider_latest_news_block_block_6227c62ef00d0\"  >\r\n\t\t\t\t\r\n\t\t\t \r\n\r\n\t\t\t\t\t  <article class=\"dbio_latest_new_posts\">  \r\n\t\t\t\t\t  <div class=\"dbio_latest_new_img\" style=\"background:url('https:\/\/dolby.io\/wp-content\/uploads\/2022\/03\/illustration-audio-research-understanding-speech-dolbyio.jpg');\">\r\n\t\t\t\t\t\t\t<a target=\"_blank\" href=\"https:\/\/webaudioconf2021.com\/workshop-b-3\/\">\r\n\t\t\t\t\t\t\t\t<h3>Understanding and visualizing speech quality<\/h3>\r\n\t\t\t\t\t\t\t\t<div class=\"featured_cs_category\">  \r\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span class=\" \">News<\/span> \r\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<svg width=\"18\" height=\"19\" viewBox=\"0 0 18 19\" fill=\"none\" xmlns=\"http:\/\/www.w3.org\/2000\/svg\">\r\n\t\t\t\t\t\t\t\t<path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M10.5 1C10.5 0.447715 10.9477 0 11.5 0H17.0001C17.2653 0 17.5197 0.105359 17.7072 0.292899C17.8947 0.480438 18.0001 0.734796 18.0001 1.00002L18 6.50002C18 7.0523 17.5523 7.50001 17 7.5C16.4477 7.49999 16 7.05227 16 6.49998L16 3.4142L9.70714 9.70711C9.31662 10.0976 8.68345 10.0976 8.29293 9.70711C7.9024 9.31658 7.9024 8.68342 8.29293 8.29289L14.5858 2H11.5C10.9477 2 10.5 1.55228 10.5 1ZM0 3.5C0 2.11929 1.11929 1 2.5 1H7C7.55228 1 8 1.44772 8 2C8 2.55228 7.55228 3 7 3H2.5C2.22386 3 2 3.22386 2 3.5V15.5109C2 15.7872 2.2241 16.0111 2.5004 16.0109L14.5004 16.0012C14.7764 16.001 15 15.7772 15 15.5012V11C15 10.4477 15.4477 10 16 10C16.5523 10 17 10.4477 17 11V15.5012C17 16.8811 15.8819 18.0001 14.502 18.0012L2.50202 18.0109C1.12052 18.012 0 16.8924 0 15.5109V3.5Z\" fill=\"white\"><\/path>\r\n\t\t\t\t\t\t\t\t<\/svg>\r\n\t\t\t\t\t\t\t\t<\/div>\r\n\t\t\t\t\t\t\t<\/a>\r\n\t\t\t\t\t  <\/div>\r\n\t\t\t\t\t  <\/article> \r\n\t\t\t\t\t  \r\n\t\t\t\t \r\n\r\n\t\t\t\t\t  <article class=\"dbio_latest_new_posts\">  \r\n\t\t\t\t\t  <div class=\"dbio_latest_new_img\" style=\"background:url('https:\/\/dolby.io\/wp-content\/uploads\/2022\/03\/illustration-audio-research-lensnet-dolbyio.jpg');\">\r\n\t\t\t\t\t\t\t<a target=\"_blank\" href=\"https:\/\/youtu.be\/pSGES0_XqaE?t=10879\">\r\n\t\t\t\t\t\t\t\t<h3>LensNet on Dolby.io<\/h3>\r\n\t\t\t\t\t\t\t\t<div class=\"featured_cs_category\">  \r\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span class=\" \">News<\/span> \r\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<svg width=\"18\" height=\"19\" viewBox=\"0 0 18 19\" fill=\"none\" xmlns=\"http:\/\/www.w3.org\/2000\/svg\">\r\n\t\t\t\t\t\t\t\t<path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M10.5 1C10.5 0.447715 10.9477 0 11.5 0H17.0001C17.2653 0 17.5197 0.105359 17.7072 0.292899C17.8947 0.480438 18.0001 0.734796 18.0001 1.00002L18 6.50002C18 7.0523 17.5523 7.50001 17 7.5C16.4477 7.49999 16 7.05227 16 6.49998L16 3.4142L9.70714 9.70711C9.31662 10.0976 8.68345 10.0976 8.29293 9.70711C7.9024 9.31658 7.9024 8.68342 8.29293 8.29289L14.5858 2H11.5C10.9477 2 10.5 1.55228 10.5 1ZM0 3.5C0 2.11929 1.11929 1 2.5 1H7C7.55228 1 8 1.44772 8 2C8 2.55228 7.55228 3 7 3H2.5C2.22386 3 2 3.22386 2 3.5V15.5109C2 15.7872 2.2241 16.0111 2.5004 16.0109L14.5004 16.0012C14.7764 16.001 15 15.7772 15 15.5012V11C15 10.4477 15.4477 10 16 10C16.5523 10 17 10.4477 17 11V15.5012C17 16.8811 15.8819 18.0001 14.502 18.0012L2.50202 18.0109C1.12052 18.012 0 16.8924 0 15.5109V3.5Z\" fill=\"white\"><\/path>\r\n\t\t\t\t\t\t\t\t<\/svg>\r\n\t\t\t\t\t\t\t\t<\/div>\r\n\t\t\t\t\t\t\t<\/a>\r\n\t\t\t\t\t  <\/div>\r\n\t\t\t\t\t  <\/article> \r\n\t\t\t\t\t  \r\n\t\t\t\t \r\n\r\n\t\t\t\t\t  <article class=\"dbio_latest_new_posts\">  \r\n\t\t\t\t\t  <div class=\"dbio_latest_new_img\" style=\"background:url('https:\/\/dolby.io\/wp-content\/uploads\/2022\/03\/illustration-audio-research-icassp-dolbyio.jpg');\">\r\n\t\t\t\t\t\t\t<a target=\"_blank\" href=\"https:\/\/twitter.com\/vivek_kumar\/status\/1401894613640753153\">\r\n\t\t\t\t\t\t\t\t<h3>Papers at ICASSP 2021<\/h3>\r\n\t\t\t\t\t\t\t\t<div class=\"featured_cs_category\">  \r\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span class=\" \">News<\/span> \r\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<svg width=\"18\" height=\"19\" viewBox=\"0 0 18 19\" fill=\"none\" xmlns=\"http:\/\/www.w3.org\/2000\/svg\">\r\n\t\t\t\t\t\t\t\t<path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M10.5 1C10.5 0.447715 10.9477 0 11.5 0H17.0001C17.2653 0 17.5197 0.105359 17.7072 0.292899C17.8947 0.480438 18.0001 0.734796 18.0001 1.00002L18 6.50002C18 7.0523 17.5523 7.50001 17 7.5C16.4477 7.49999 16 7.05227 16 6.49998L16 3.4142L9.70714 9.70711C9.31662 10.0976 8.68345 10.0976 8.29293 9.70711C7.9024 9.31658 7.9024 8.68342 8.29293 8.29289L14.5858 2H11.5C10.9477 2 10.5 1.55228 10.5 1ZM0 3.5C0 2.11929 1.11929 1 2.5 1H7C7.55228 1 8 1.44772 8 2C8 2.55228 7.55228 3 7 3H2.5C2.22386 3 2 3.22386 2 3.5V15.5109C2 15.7872 2.2241 16.0111 2.5004 16.0109L14.5004 16.0012C14.7764 16.001 15 15.7772 15 15.5012V11C15 10.4477 15.4477 10 16 10C16.5523 10 17 10.4477 17 11V15.5012C17 16.8811 15.8819 18.0001 14.502 18.0012L2.50202 18.0109C1.12052 18.012 0 16.8924 0 15.5109V3.5Z\" fill=\"white\"><\/path>\r\n\t\t\t\t\t\t\t\t<\/svg>\r\n\t\t\t\t\t\t\t\t<\/div>\r\n\t\t\t\t\t\t\t<\/a>\r\n\t\t\t\t\t  <\/div>\r\n\t\t\t\t\t  <\/article> \r\n\t\t\t\t\t  \r\n\t\t\t\t \r\n\r\n\t\t\t\t\t  <article class=\"dbio_latest_new_posts\">  \r\n\t\t\t\t\t  <div class=\"dbio_latest_new_img\" style=\"background:url('https:\/\/dolby.io\/wp-content\/uploads\/2022\/03\/illustration-audio-research-upsampling-artifacts-dolbyio.jpg');\">\r\n\t\t\t\t\t\t\t<a target=\"_blank\" href=\"https:\/\/webaudioconf2021.com\/workshop-b-3\/\">\r\n\t\t\t\t\t\t\t\t<h3>Upsampling artifacts in neural audio synthesis<\/h3>\r\n\t\t\t\t\t\t\t\t<div class=\"featured_cs_category\">  \r\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span class=\" \">Talk<\/span> \r\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<svg width=\"18\" height=\"19\" viewBox=\"0 0 18 19\" fill=\"none\" xmlns=\"http:\/\/www.w3.org\/2000\/svg\">\r\n\t\t\t\t\t\t\t\t<path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M10.5 1C10.5 0.447715 10.9477 0 11.5 0H17.0001C17.2653 0 17.5197 0.105359 17.7072 0.292899C17.8947 0.480438 18.0001 0.734796 18.0001 1.00002L18 6.50002C18 7.0523 17.5523 7.50001 17 7.5C16.4477 7.49999 16 7.05227 16 6.49998L16 3.4142L9.70714 9.70711C9.31662 10.0976 8.68345 10.0976 8.29293 9.70711C7.9024 9.31658 7.9024 8.68342 8.29293 8.29289L14.5858 2H11.5C10.9477 2 10.5 1.55228 10.5 1ZM0 3.5C0 2.11929 1.11929 1 2.5 1H7C7.55228 1 8 1.44772 8 2C8 2.55228 7.55228 3 7 3H2.5C2.22386 3 2 3.22386 2 3.5V15.5109C2 15.7872 2.2241 16.0111 2.5004 16.0109L14.5004 16.0012C14.7764 16.001 15 15.7772 15 15.5012V11C15 10.4477 15.4477 10 16 10C16.5523 10 17 10.4477 17 11V15.5012C17 16.8811 15.8819 18.0001 14.502 18.0012L2.50202 18.0109C1.12052 18.012 0 16.8924 0 15.5109V3.5Z\" fill=\"white\"><\/path>\r\n\t\t\t\t\t\t\t\t<\/svg>\r\n\t\t\t\t\t\t\t\t<\/div>\r\n\t\t\t\t\t\t\t<\/a>\r\n\t\t\t\t\t  <\/div>\r\n\t\t\t\t\t  <\/article> \r\n\t\t\t\t\t  \r\n\t\t\t\t\t\t<\/div> \r\n\t<\/section>\t\t\t \r\n<\/section> \n\n\n<section id=\"ctablock_block_6148e88e0a133\" class=\"dbio_blocks ctablock_container force_fullscreen_width dbio_light_theme default-bg\"  style=\"background-image: url(\/wp-content\/themes\/altitude-pro\/blocks\/cta_block\/cta_default_background.jpg);\">\n\n<div class=\"ctablock dbio-animate \">\n\n  \r\n<div class=\"dbio-default-heading-block\">\r\n      <div class=\"dbio-eyebrow-headline\">Careers at Dolby<\/div>\r\n    <h2>Join the Dolby Applied AI team<\/h2>\r\n<\/div>\r\n\n    <p class=\"dbio_regular_paragraph\">We are always looking to incorporate the greatest minds into our AI team.rnrn<\/p>\n\n    <div class=\"dbio_cta_row\">\n        \n  <div class=\"dbio-default-button-container\">\n    <a href=\"https:\/\/jobs.dolby.com\/careers?query=applied%2Bai\" target=\"_self\" class=\"dbio-default-button dbio-outlined-button\">Explore open roles      <span class=\"outlined_alt_hover_effect\">Explore open roles<\/span>\n    <\/a>\n  <\/div>\n\n\n        \n    <\/div>\n\n  <\/div>\n\n<\/section>\n<style>\n\n#ctablock_block_6148e88e0a133.ctablock_container.dbio_light * {\n  color: #fff;\n}\n#ctablock_block_6148e88e0a133.ctablock_container.dbio_light svg path {\n  stroke: #fff;\n}\n\n#ctablock_block_6148e88e0a133.ctablock_container.dbio_light .dbio-default-button {\n  box-shadow: 0px 4px 8px 0px #6161612E;\n  box-shadow: 0px 2px 4px 0px #6161612E;\n}\n\n<\/style>\n\n\n\n<div class=\"wp-block-genesis-blocks-gb-columns gb-layout-columns-2 gb-2-col-equal gb-has-custom-background-color gb-columns-center alignfull\" style=\"padding-right:1.5em;padding-left:1.5em;background-color:#14141a\"><div class=\"gb-layout-column-wrap gb-block-layout-column-gap-2 gb-is-responsive-column\" style=\"max-width:1200px\">\n<div class=\"wp-block-genesis-blocks-gb-column gb-block-layout-column\"><div class=\"gb-block-layout-column-inner gb-has-custom-background-color\" style=\"padding-top:44px;padding-bottom:22px;background-color:#14141a\">\n<h4 class=\"has-text-color\" id=\"h-keep-a-good-thing-going\" style=\"color:#ffffff\">Keep a good thing going<\/h4>\n\n\n\n<p class=\"has-text-color\" style=\"color:#eeeeee\">Get the latest news, events, and product updates from the Dolby.io team.<\/p>\n<\/div><\/div>\n\n\n\n<div class=\"wp-block-genesis-blocks-gb-column news-c gb-block-layout-column\"><div class=\"gb-block-layout-column-inner\">\n\n\t\t\t\t\t<script>\n\t\t\t\t\t\thbspt.enqueueForm({\n\t\t\t\t\t\t\tportalId: 14544730,\n\t\t\t\t\t\t\tformId: \"976cc077-7102-463d-a845-7be658bdc57f\",\n\t\t\t\t\t\t\ttarget: \"#hbspt-form-1651860128000-5957286407\",\n\t\t\t\t\t\t\tregion: \"\",\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t});\n\t\t\t\t\t<\/script>\n\t\t\t\t\t<div class=\"hbspt-form\" id=\"hbspt-form-1651860128000-5957286407\"><\/div>\n<\/div><\/div>\n<\/div><\/div>\n\n\n\n<div class=\"wp-block-genesis-blocks-gb-columns dbio-wave-rule gb-layout-columns-1 one-column gb-columns-center alignfull\" style=\"margin-top:52px;padding-top:6px;padding-bottom:6px\"><div class=\"gb-layout-column-wrap gb-block-layout-column-gap-0 gb-is-responsive-column\" style=\"max-width:1313px\">\n<div class=\"wp-block-genesis-blocks-gb-column gb-block-layout-column gb-is-vertically-aligned-bottom\"><div class=\"gb-block-layout-column-inner gb-has-custom-background-color\" style=\"margin-top:50px;padding-top:6px;background-color:#14141a;text-align:center\">\n<figure class=\"wp-block-image alignfull size-full\"><img loading=\"lazy\" width=\"1312\" height=\"12\" src=\"https:\/\/dolbydev.wpengine.com\/wp-content\/uploads\/2021\/09\/DolbyIO-Wave-Separator-White.png\" alt=\"\" class=\"wp-image-2579\" srcset=\"https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/DolbyIO-Wave-Separator-White.png 1312w, https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/DolbyIO-Wave-Separator-White-300x3.png 300w, https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/DolbyIO-Wave-Separator-White-1024x9.png 1024w, https:\/\/dolby.io\/wp-content\/uploads\/2021\/09\/DolbyIO-Wave-Separator-White-768x7.png 768w\" sizes=\"(max-width: 1312px) 100vw, 1312px\" \/><\/figure>\n<\/div><\/div>\n<\/div><\/div>\n\n\n\n<p><\/p>\n","protected":false},"excerpt":{"rendered":"","protected":false},"author":1,"featured_media":0,"parent":0,"menu_order":0,"comment_status":"closed","ping_status":"closed","template":"","meta":{"inline_featured_image":false,"_genesis_hide_title":true,"_genesis_hide_breadcrumbs":false,"_genesis_hide_singular_image":false,"_genesis_hide_footer_widgets":false,"_genesis_custom_body_class":"front-page featured-section","_genesis_custom_post_class":"","_genesis_layout":""},"acf":[],"yoast_head":"<!-- This site is optimized with the Yoast SEO Premium plugin v17.2 (Yoast SEO v18.5.1) - https:\/\/yoast.com\/wordpress\/plugins\/seo\/ -->\n<title>Audio Research - Dolby.io<\/title>\n<meta name=\"description\" content=\"We\u2019re advancing the latest breakthroughs in audio AI The Dolby Applied AI team advances the state of the art in audio processing byusing and developing\" \/>\n<meta name=\"robots\" content=\"index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1\" \/>\n<link rel=\"canonical\" href=\"https:\/\/dolby.io\/audio-research\/\" \/>\n<meta property=\"og:locale\" content=\"en_US\" \/>\n<meta property=\"og:type\" content=\"article\" \/>\n<meta property=\"og:title\" content=\"Audio Research\" \/>\n<meta property=\"og:description\" content=\"The Dolby Applied AI team advances the state of the art in audio processing byusing and developing core AI techniqu\" \/>\n<meta property=\"og:url\" content=\"https:\/\/dolby.io\/audio-research\/\" \/>\n<meta property=\"og:site_name\" content=\"Dolby.io\" \/>\n<meta property=\"article:modified_time\" content=\"2022-03-09T17:20:56+00:00\" \/>\n<meta property=\"og:image\" content=\"https:\/\/staging.dolbyio.com\/wp-content\/uploads\/2022\/03\/illustration-audio-research-approach-dolbyio.png\" \/>\n<meta name=\"twitter:card\" content=\"summary_large_image\" \/>\n<meta name=\"twitter:description\" content=\"We\u2019re advancing the latest breakthroughs in audio AI The Dolby Applied AI team advances the state of the art in audio processing byusing and developing\" \/>\n<meta name=\"twitter:label1\" content=\"Est. reading time\" \/>\n\t<meta name=\"twitter:data1\" content=\"1 minute\" \/>\n<script type=\"application\/ld+json\" class=\"yoast-schema-graph\">{\"@context\":\"https:\/\/schema.org\",\"@graph\":[{\"@type\":\"Organization\",\"@id\":\"https:\/\/dolby.io\/#organization\",\"name\":\"Dolby.io\",\"url\":\"https:\/\/dolby.io\/\",\"sameAs\":[],\"logo\":{\"@type\":\"ImageObject\",\"@id\":\"https:\/\/dolby.io\/#logo\",\"inLanguage\":\"en-US\",\"url\":\"https:\/\/dolby.io\/wp-content\/uploads\/2021\/07\/DolbyIO-favicon.png\",\"contentUrl\":\"https:\/\/dolby.io\/wp-content\/uploads\/2021\/07\/DolbyIO-favicon.png\",\"width\":512,\"height\":512,\"caption\":\"Dolby.io\"},\"image\":{\"@id\":\"https:\/\/dolby.io\/#logo\"}},{\"@type\":\"WebSite\",\"@id\":\"https:\/\/dolby.io\/#website\",\"url\":\"https:\/\/dolby.io\/\",\"name\":\"Dolby.io\",\"description\":\"Dolby.io\",\"publisher\":{\"@id\":\"https:\/\/dolby.io\/#organization\"},\"potentialAction\":[{\"@type\":\"SearchAction\",\"target\":{\"@type\":\"EntryPoint\",\"urlTemplate\":\"https:\/\/dolby.io\/?s={search_term_string}\"},\"query-input\":\"required name=search_term_string\"}],\"inLanguage\":\"en-US\"},{\"@type\":\"ImageObject\",\"@id\":\"https:\/\/dolby.io\/audio-research\/#primaryimage\",\"inLanguage\":\"en-US\",\"url\":\"https:\/\/staging.dolbyio.com\/wp-content\/uploads\/2022\/03\/illustration-audio-research-approach-dolbyio.png\",\"contentUrl\":\"https:\/\/staging.dolbyio.com\/wp-content\/uploads\/2022\/03\/illustration-audio-research-approach-dolbyio.png\"},{\"@type\":\"WebPage\",\"@id\":\"https:\/\/dolby.io\/audio-research\/#webpage\",\"url\":\"https:\/\/dolby.io\/audio-research\/\",\"name\":\"Audio Research - Dolby.io\",\"isPartOf\":{\"@id\":\"https:\/\/dolby.io\/#website\"},\"primaryImageOfPage\":{\"@id\":\"https:\/\/dolby.io\/audio-research\/#primaryimage\"},\"datePublished\":\"2022-03-08T21:40:38+00:00\",\"dateModified\":\"2022-03-09T17:20:56+00:00\",\"description\":\"We\u2019re advancing the latest breakthroughs in audio AI The Dolby Applied AI team advances the state of the art in audio processing byusing and developing\",\"breadcrumb\":{\"@id\":\"https:\/\/dolby.io\/audio-research\/#breadcrumb\"},\"inLanguage\":\"en-US\",\"potentialAction\":[{\"@type\":\"ReadAction\",\"target\":[\"https:\/\/dolby.io\/audio-research\/\"]}]},{\"@type\":\"BreadcrumbList\",\"@id\":\"https:\/\/dolby.io\/audio-research\/#breadcrumb\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"Home\",\"item\":\"https:\/\/dolby.io\/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"Audio Research\"}]}]}<\/script>\n<!-- \/ Yoast SEO Premium plugin. -->","yoast_head_json":{"title":"Audio Research - Dolby.io","description":"We\u2019re advancing the latest breakthroughs in audio AI The Dolby Applied AI team advances the state of the art in audio processing byusing and developing","robots":{"index":"index","follow":"follow","max-snippet":"max-snippet:-1","max-image-preview":"max-image-preview:large","max-video-preview":"max-video-preview:-1"},"canonical":"https:\/\/dolby.io\/audio-research\/","og_locale":"en_US","og_type":"article","og_title":"Audio Research","og_description":"The Dolby Applied AI team advances the state of the art in audio processing byusing and developing core AI techniqu","og_url":"https:\/\/dolby.io\/audio-research\/","og_site_name":"Dolby.io","article_modified_time":"2022-03-09T17:20:56+00:00","og_image":[{"url":"https:\/\/staging.dolbyio.com\/wp-content\/uploads\/2022\/03\/illustration-audio-research-approach-dolbyio.png"}],"twitter_card":"summary_large_image","twitter_description":"We\u2019re advancing the latest breakthroughs in audio AI The Dolby Applied AI team advances the state of the art in audio processing byusing and developing","twitter_misc":{"Est. reading time":"1 minute"},"schema":{"@context":"https:\/\/schema.org","@graph":[{"@type":"Organization","@id":"https:\/\/dolby.io\/#organization","name":"Dolby.io","url":"https:\/\/dolby.io\/","sameAs":[],"logo":{"@type":"ImageObject","@id":"https:\/\/dolby.io\/#logo","inLanguage":"en-US","url":"https:\/\/dolby.io\/wp-content\/uploads\/2021\/07\/DolbyIO-favicon.png","contentUrl":"https:\/\/dolby.io\/wp-content\/uploads\/2021\/07\/DolbyIO-favicon.png","width":512,"height":512,"caption":"Dolby.io"},"image":{"@id":"https:\/\/dolby.io\/#logo"}},{"@type":"WebSite","@id":"https:\/\/dolby.io\/#website","url":"https:\/\/dolby.io\/","name":"Dolby.io","description":"Dolby.io","publisher":{"@id":"https:\/\/dolby.io\/#organization"},"potentialAction":[{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https:\/\/dolby.io\/?s={search_term_string}"},"query-input":"required name=search_term_string"}],"inLanguage":"en-US"},{"@type":"ImageObject","@id":"https:\/\/dolby.io\/audio-research\/#primaryimage","inLanguage":"en-US","url":"https:\/\/staging.dolbyio.com\/wp-content\/uploads\/2022\/03\/illustration-audio-research-approach-dolbyio.png","contentUrl":"https:\/\/staging.dolbyio.com\/wp-content\/uploads\/2022\/03\/illustration-audio-research-approach-dolbyio.png"},{"@type":"WebPage","@id":"https:\/\/dolby.io\/audio-research\/#webpage","url":"https:\/\/dolby.io\/audio-research\/","name":"Audio Research - Dolby.io","isPartOf":{"@id":"https:\/\/dolby.io\/#website"},"primaryImageOfPage":{"@id":"https:\/\/dolby.io\/audio-research\/#primaryimage"},"datePublished":"2022-03-08T21:40:38+00:00","dateModified":"2022-03-09T17:20:56+00:00","description":"We\u2019re advancing the latest breakthroughs in audio AI The Dolby Applied AI team advances the state of the art in audio processing byusing and developing","breadcrumb":{"@id":"https:\/\/dolby.io\/audio-research\/#breadcrumb"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https:\/\/dolby.io\/audio-research\/"]}]},{"@type":"BreadcrumbList","@id":"https:\/\/dolby.io\/audio-research\/#breadcrumb","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https:\/\/dolby.io\/"},{"@type":"ListItem","position":2,"name":"Audio Research"}]}]}},"uagb_featured_image_src":{"full":false,"thumbnail":false,"medium":false,"medium_large":false,"large":false,"1536x1536":false,"2048x2048":false,"featured-page":false,"gb-block-post-grid-landscape":false,"gb-block-post-grid-square":false},"uagb_author_info":{"display_name":"dolbyio","author_link":"https:\/\/dolby.io\/blog\/author\/dolbyio\/"},"uagb_comment_info":0,"uagb_excerpt":null,"featured_image_src":null,"featured_image_src_square":null,"_links":{"self":[{"href":"https:\/\/dolby.io\/wp-json\/wp\/v2\/pages\/5342"}],"collection":[{"href":"https:\/\/dolby.io\/wp-json\/wp\/v2\/pages"}],"about":[{"href":"https:\/\/dolby.io\/wp-json\/wp\/v2\/types\/page"}],"author":[{"embeddable":true,"href":"https:\/\/dolby.io\/wp-json\/wp\/v2\/users\/1"}],"replies":[{"embeddable":true,"href":"https:\/\/dolby.io\/wp-json\/wp\/v2\/comments?post=5342"}],"version-history":[{"count":0,"href":"https:\/\/dolby.io\/wp-json\/wp\/v2\/pages\/5342\/revisions"}],"wp:attachment":[{"href":"https:\/\/dolby.io\/wp-json\/wp\/v2\/media?parent=5342"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}